{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from game import Board, ACTION_SIZE, rotate, rotate_bundle\n",
    "from model import NNet, MCTS\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "import os\n",
    "print(\"pid=%d\"%os.getpid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = None\n",
    "\n",
    "def count_data(mcts: MCTS):\n",
    "    count=0\n",
    "    for key in mcts.Ns:\n",
    "        if mcts.Ns[key] > 10:\n",
    "            count+=1\n",
    "    return count\n",
    "\n",
    "def self_play(mcts: MCTS, batch_num=100, timeout=10):\n",
    "    global debug\n",
    "    for batch in range(batch_num):\n",
    "        print(f\"Batch {batch}\")\n",
    "        num = count_data(mcts)\n",
    "        if num > 10000:\n",
    "            print(\"Data is enough, break\", num, \">\", 10000)\n",
    "            break\n",
    "        else:\n",
    "            print(\"Data is not enough, continue self play\", num, \"<\", 10000)\n",
    "        board = Board()\n",
    "        for i in range(100):\n",
    "            debug = board.copy()\n",
    "            action = mcts.best_move(board, timeout)\n",
    "            c = board.color\n",
    "            v = mcts.query_v(board, action)\n",
    "            board.place(*board.int2move(action))\n",
    "            if hasattr(board, \"winner\"):\n",
    "                break\n",
    "            print(str(board))\n",
    "            print(f\"Color: {'O_X'[c+1]}, Action: {action}, Value: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ver = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_mcts(mcts, filename):\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(\n",
    "            {\n",
    "                \"Ps\": mcts.Ps,\n",
    "                \"Ns\": mcts.Ns,\n",
    "                \"Qsa\": mcts.Qsa,\n",
    "                \"Nsa\": mcts.Nsa,\n",
    "            }, f)\n",
    "def load_mcts(mcts, filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "        mcts.Ps = data[\"Ps\"]\n",
    "        mcts.Ns = data[\"Ns\"]\n",
    "        mcts.Qsa = data[\"Qsa\"]\n",
    "        mcts.Nsa = data[\"Nsa\"]\n",
    "def get_data(mcts: MCTS):\n",
    "    key_list = list(mcts.Ns.keys())\n",
    "    weight_list = [mcts.Ns[key] for key in key_list]\n",
    "    sum = np.sum(weight_list)\n",
    "    weight_list = [w/sum for w in weight_list]\n",
    "    key_choose = np.random.choice(range(len(key_list)), 20000, replace=True, p=weight_list)\n",
    "    data = []\n",
    "    \n",
    "    for id in tqdm(key_choose):\n",
    "        key = key_list[id]\n",
    "        board = Board.from_state(key)\n",
    "        input = board.bundled_input(board.legal_moves_input())\n",
    "        ps = np.zeros(ACTION_SIZE)\n",
    "        action = mcts.best_move(board, timeout=0)\n",
    "        ps[action] = 1.0\n",
    "        vs = mcts.Qsa[key, action]\n",
    "        for i in range(4):\n",
    "            data.append((\n",
    "                input,\n",
    "                ps,\n",
    "                float(vs)\n",
    "                )\n",
    "            )\n",
    "            input = rotate_bundle(input, board.n)\n",
    "            last = ps[-1]\n",
    "            ps = np.array(rotate(ps[:-1], board.n).tolist() + [last])\n",
    "    return data\n",
    "\n",
    "def train_network(data, epoch_num=1000, pi_only=False):\n",
    "    map_location = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    device = torch.device(map_location)\n",
    "    saved_state = torch.load(\"data/cnn.pt\", map_location=map_location)\n",
    "    nnet = NNet(0, 128, 256).to(device)\n",
    "    nnet.load_state_dict(saved_state)\n",
    "\n",
    "    data_input = torch.tensor(np.array([d[0] for d in data]), dtype=torch.float32).to(device)\n",
    "    data_output1, data_output2 = \\\n",
    "        torch.tensor(np.array([d[1] for d in data]), dtype=torch.float32).to(device), \\\n",
    "        torch.tensor(np.array([d[2] for d in data]), dtype=torch.float32).to(device)\n",
    "    data_output1 = data_output1.view(-1, ACTION_SIZE)\n",
    "    data_output2 = data_output2.view(-1, 1)\n",
    "\n",
    "    # train nnet with data\n",
    "    optimizer = optim.Adam(nnet.parameters(), lr=0.0005, weight_decay=1e-4)\n",
    "    for epoch in range(epoch_num):\n",
    "        optimizer.zero_grad()\n",
    "        output1, output2 = nnet(data_input)\n",
    "        if not pi_only:\n",
    "            # 计算交叉熵\n",
    "            loss1 = torch.mean(-data_output1 * output1)\n",
    "            loss2 = nn.MSELoss()(output2, data_output2)\n",
    "            # 分别训练 loss1 和 loss2\n",
    "            loss = loss1 + loss2\n",
    "        else:\n",
    "            loss = torch.mean(-data_output1 * output1)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if not pi_only:\n",
    "            print(f'Epoch {epoch}, Loss1: {loss1.item()}, Loss2: {loss2.item()}')\n",
    "        else:\n",
    "            print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "\n",
    "    # save nnet\n",
    "    torch.save(nnet.state_dict(), \"data/cnn.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet = NNet(0, 128, 256)\n",
    "saved_state = torch.load(\"data/cnn.pt\", map_location='cpu')\n",
    "nnet.load_state_dict(saved_state)\n",
    "mcts = MCTS(nnet)\n",
    "self_play(mcts, timeout=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnet = NNet(0, 128, 256)\n",
    "while True:\n",
    "    print('----------------------------------')\n",
    "    saved_state = torch.load(\"data/cnn.pt\", map_location='cpu')\n",
    "    nnet.load_state_dict(saved_state)\n",
    "    mcts = MCTS(nnet)\n",
    "    self_play(mcts, timeout=4)\n",
    "    print('Count Data: ', count_data(mcts))\n",
    "    data = get_data(mcts)\n",
    "    with open(f\"data{ver}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(data, f)\n",
    "    train_network(data[0:50000], epoch_num=20)\n",
    "    train_network(data[50000:100000], epoch_num=20)\n",
    "    train_network(data[100000:150000], epoch_num=20)\n",
    "    train_network(data[150000:200000], epoch_num=20)\n",
    "    ver += 1\n",
    "    del mcts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiphy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
